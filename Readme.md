
# ğŸ“ Text Collection System

A powerful tool to:
1. Add, view, and search texts with **automatic tags**. 
2. ğŸ•µï¸â€â™‚ï¸ Crawl Wikipedia articles directly into your collection.
3. ğŸŒ Provide an API to fetch articles and their tags.

---

## ğŸš€ Features
- **Streamlit App**: Add, search, and manage texts easily.
- **Automatic Tagging**: Tags generated using AI-powered `spaCy`.
- **FastAPI**: Access your texts programmatically with filtering options.

---

## ğŸ›  Setup

### Prerequisites
- Python 3.8+
- pip

### Install Dependencies
```bash
pip install -r requirements.txt
```

---

## ğŸ’» Run the Streamlit App
1. **Install SpaCy Model**:
   ```bash
   python -m spacy download en_core_web_sm
   ```
2. **Start the App**:
   ```bash
   streamlit run main.py
   ```
3. Access it in your browser: [http://localhost:8501](http://localhost:8501)

---

## ğŸŒ Run the API
1. **Start the API Server**:
   ```bash
   uvicorn api:app --reload
   ```
2. Access the API at: [http://127.0.0.1:8000/articles](http://127.0.0.1:8000/articles)

### API Query Parameters:
- `query`: Search for a keyword in text.
- `tag`: Filter by tag.

#### Examples:
- All articles:  
  ```bash
  curl http://127.0.0.1:8000/articles
  ```
- Search by keyword:  
  ```bash
  curl "http://127.0.0.1:8000/articles?query=example"
  ```
- Filter by tag:  
  ```bash
  curl "http://127.0.0.1:8000/articles?tag=demo"
  ```

---

## ğŸ“‚ Project Structure
```plaintext
.
â”œâ”€â”€ api.py          # FastAPI service
â”œâ”€â”€ main.py         # Streamlit application
â”œâ”€â”€ db.py           # Database logic
â”œâ”€â”€ analyzer.py     # Automatic tag generation
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

---

## ğŸ¤ Contributing
1. Fork it ğŸ´  
2. Create a branch: `git checkout -b my-feature`  
3. Commit changes: `git commit -m 'Add feature ğŸš€'`  
4. Push: `git push origin my-feature`  
5. Open a PR!

